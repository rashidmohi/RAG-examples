{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Yisheng - A natural healing doctor using RAG**\n",
    "This is the example of how an LLM can be used together with the custom data to answer specialized questions related to a field of interest. In this example, we'll minimize the use of higher level methods and libraries to show the basic steps involved in the RAG. I have used the Google Gemini API as it offers generous free-tier for the developers unlike OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Import the Libraries and load the environment variables\n",
    "First code block is to supress the warning messages. Then we import the libraries and load the GOOGLE_API_KEY from .env file.   \n",
    " \n",
    "*remember to add your .env to the .gitignore*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain.document_loaders.json_loader import JSONLoader\n",
    "from langchain import PromptTemplate\n",
    "from langchain_community.vectorstores.faiss import FAISS\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "DEBUG = False\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "if DEBUG:\n",
    "    os.environ[\"GOOGLE_API_KEY\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- Create the LLM Object\n",
    "We'll create 2 models   \n",
    "\n",
    "1. The generative/Chat model for the response creation\n",
    "2. The embedding model to vectorize the retrieval data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the generative model for the response creation. You can adjust the temperature to control the randomness of the response  \n",
    "llm = GoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    temperature=0.7,\n",
    "    )\n",
    "\n",
    "# the embeddings model for the vectorization of the data\n",
    "embeddings_model = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"models/embedding-001\"\n",
    "    )\n",
    "\n",
    "if DEBUG:\n",
    "    print(llm.invoke(\"Tell me a joke\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3- Load the JSON data file\n",
    "A simple json data file with ailments and home remedies data. Load the data as the ground truth for the response to queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract the page_content from Document object and convert to list of strings\n",
    "def extract_text_column(documents, column_name):\n",
    "    text_list = []\n",
    "    for doc in documents:\n",
    "        text_list.append(doc.page_content)\n",
    "    return text_list\n",
    "\n",
    "# Load the data from the json file\n",
    "dataloader = JSONLoader(\n",
    "    file_path='remedies2.jsonl',\n",
    "    jq_schema='.Remedy',\n",
    "    text_content=False,\n",
    "    json_lines=True\n",
    "    )\n",
    "\n",
    "data = dataloader.load()\n",
    "\n",
    "# convert to text list for the vectorization\n",
    "text_list = extract_text_column(data, 'page_content')\n",
    "\n",
    "if DEBUG:\n",
    "    print(text_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4- Vectorize the data and store in Vector Database    \n",
    "Now it's time to vectorize the data and store in the vector database. I have picked FAISS for the convenience. You can select other databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    embeddings = embeddings_model.embed_documents(text_list)\n",
    "    print(\"Embed documents:\")\n",
    "    print(f\"Number of vector: {len(embeddings)}; Dimension of each vector: {len(embeddings[0])}\")\n",
    "\n",
    "# Create the vector store\n",
    "vector_store = FAISS.from_texts(text_list,embeddings_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5- Take the user input and query the vector store\n",
    "Take the user input and perform similarity search on the vector store to retrieve matching records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The remedies for Cold are Ginger tea and Cloves\n"
     ]
    }
   ],
   "source": [
    "#get your questions\n",
    "user_question = input(\"Please enter your question\")\n",
    "match = vector_store.similarity_search(user_question)\n",
    "print(match[0].page_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6- Generate the human-like response using the LLM\n",
    "And finally we'll generate the friendly response by engineering the prompt and invoking LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ah, a nasty cold has taken hold, has it?  Don't you worry, my dear.  Nature provides many gentle remedies to soothe those sniffles and chase away the chills.  The wise ones, and I count myself among them, have long known the power of ginger and cloves in combating the common cold.\n",
      "\n",
      "Let's talk about these two potent allies:\n",
      "\n",
      "**Ginger:** This warming root is a true marvel. It possesses potent anti-inflammatory properties, helping to reduce the congestion that often accompanies a cold.  The warmth itself can be incredibly soothing, easing the aches and pains that often accompany a cold.\n",
      "\n",
      "* **How to use it:** I recommend a simple ginger tea.  Take a knob of fresh ginger – about an inch or two – and finely grate it.  Steep this in a cup of boiling water for 10-15 minutes. You can add a touch of honey or lemon for extra sweetness and vitamin C, but avoid dairy as it can increase mucus production. Sip this warm tea throughout the day.  The spiciness will clear your sinuses and the warmth will comfort you.\n",
      "\n",
      "**Cloves:** These little brown buds are powerhouses of medicinal properties.  They are rich in eugenol, a compound with antiseptic and analgesic properties. This helps to fight off infection and numb any sore throat discomfort.\n",
      "\n",
      "* **How to use them:** You can add a few whole cloves to your ginger tea for an extra boost.  The subtle, warm flavor complements the ginger beautifully. Alternatively, you can chew on a single clove slowly; the numbing effect will help soothe a scratchy throat, but be mindful not to swallow it whole.\n",
      "\n",
      "**Important Considerations:**\n",
      "\n",
      "* **Hydration is key:**  Drink plenty of fluids – water, herbal teas, broths – to help thin mucus and flush out toxins.\n",
      "* **Rest is essential:** Your body needs time to heal. Get plenty of sleep to support your immune system.\n",
      "* **Listen to your body:** If your symptoms worsen or persist for an extended period, it's always best to consult a qualified physician.  These remedies are supportive, not replacements, for professional medical advice.\n",
      "\n",
      "Remember, these natural remedies are best used as part of a holistic approach to wellness. Combining them with rest, hydration, and a healthy diet will help your body fight off the cold naturally and effectively.  Take care, and may you find swift relief!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create the prompt text\n",
    "remedy_template = \"\"\"You are a traditional medic who advises based on natural healing methods and home remedies. \\\n",
    "You help people understanding the natural healing methods based on the expert advice given to you\n",
    "\n",
    "Here is the expert advise for you:\n",
    "{advice}\"\"\"\n",
    "\n",
    "\n",
    "# Create the prompt template with a variable input\n",
    "prompt_template = PromptTemplate(template=remedy_template)\n",
    "\n",
    "\n",
    "# Function to generate a prompt with the given input\n",
    "def generate_prompt(advice):\n",
    "    return prompt_template.format(advice=advice)\n",
    "\n",
    "# Generate the prompt\n",
    "prompt = generate_prompt(match[0].page_content)\n",
    "\n",
    "# Invoke Google Gemini for the response\n",
    "response = llm.invoke(prompt)\n",
    "\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
